---
layout: post.njk
title: La IA está destruyendo al planeta
date: 2024-07-26
permalink: "/blog/la-ia-esta-destruyendo-al-planeta/"
featured: "/static/posts/20240727_la-ia-esta-destruyendo-al-planeta/featured.jpeg"
tags: post
---

Desde la invención de la computadora ha habido el interés de crear máquinas que "imiten" al comportamiento humano, o que ejecuten operaciones comparables a las que realiza la mente humana, como el aprendizaje o el razonamiento lógico [[1](https://dle.rae.es/inteligencia)]. Ya en 1950 Alan Turing había diseñado una "prueba" que mide la capacidad de una máquina de hacer creer que es un ser humano [[2](https://www.turing.org.uk/scrapbook/test.html)], herramienta que se bautizó con [su nombre](https://es.wikipedia.org/wiki/Prueba_de_Turing), y cuya forma más popular hoy en día es el [CAPTCHA](https://es.wikipedia.org/wiki/Captcha).

En la década del 2010 la inteligencia artificial ya era ampliamente usada en Internet. Desde chatbots, herramientas de tracking, computadoras que juegan ajedrez y Go, hasta sistemas automatizados para [web scraping](https://es.wikipedia.org/wiki/Web_scraping), "asistentes virtuales" como Cortana, Siri o Alexa, así como usos en la medicina y la ingeniería (especialmente la robótica y la mecatrónica). El mal llamado "algoritmo" tan característico de las redes sociales privativas no es más que una inteligencia artificial que "estudia" el comportamiento de los usuarios de dichas redes, para así crearles un "perfil" que después sirva para ponerles anuncios, recomendarles contenido de su interés [[3](https://www.mediummultimedia.com/social-media/como-funcionan-los-algoritmos-de-las-redes-sociales/)] y, en última instancia, [manipularlos](https://es.wikipedia.org/wiki/Esc%C3%A1ndalo_de_datos_de_Facebook-Cambridge_Analytica#Uso_de_datos).

Sin embargo, fue a partir de la década del 2020, en la cual ya casi vamos a la mitad, que comenzó el _boom_ de la inteligencia artificial. Usando modelos de [_deep learning_](https://es.wikipedia.org/wiki/Aprendizaje_profundo) se puede crear un [modelo de lenguaje grande](https://es.wikipedia.org/wiki/Modelo_de_lenguaje_grande), mejor conocido como LLM por sus siglas en inglés, que es un tipo de IA generativa (es decir, que _genera_ contenido) a partir del entrenamiento adquirido de analizar cantidades industriales de texto de cualquier tipo. Siendo los LLM más populares los modelos GPT, PaLM, Gemini y Claude.

No es ningún secreto que las inteligencias artificiales generativas dan muchos más problemas que soluciones. ChatGPT es conocido por proporcionar datos erróneos y hacerlos pasar por verdaderos (cosa que se conoce como [_alucinación_ de datos](https://es.wikipedia.org/wiki/Alucinaci%C3%B3n_(inteligencia_artificial))), y otros tipos de IA son capaces de generar [imágenes tan realistas](https://www.rtve.es/noticias/20230328/como-detectamos-imagenes-generadas-por-inteligencia-artificial/2433428.shtml) que resulta difícil diferenciarlas de fotografías reales, con lo que se vuelve ridículamente fácil la creación y viralización de _fake news_.

Además, las grandes multinacionales están presionando cada vez más la incorporación de la IA en sus productos; Microsoft no dudó en agregar su propia versión de GPT en Windows 11, Meta acaba de hacer lo mismo con Facebook, Instagram y Whatsapp, y ya hasta DuckDuckGo tiene su propia IA. Además de los problemas ya mencionados, la inteligencia artificial también se está utilizando como instrumento de vigilancia permanente del cual es cada vez más difícil escapar, pero hay algo muchísimo peor, y que no parece importarle a nadie.

Por un lado tenemos la situación en la que la IA está haciendo que el ser humano comience a _evadir_ al pensamiento. En escuelas y universidades de todo el mundo ya es un problema global el uso de ChatGPT para hacer trampa en exámenes y redactar toda clase de artículos académicos y ensayos sin esfuerzo [[4](https://www.abc.net.au/news/science/2023-11-22/how-high-school-students-used-chatgpt-2023-education-cheating/103108620)]; mi propia universidad está teniendo muchísimos problemas para luchar en contra de ello, y a pesar de que se ha tratado de tomar medidas, tales como reprobar a los alumnos que usan la IA de manera desmedida, cada que hay un examen parcial miro a mi alrededor y veo a la mayoría de mis compañeros con la página de color gris oscuro y de logotipo verde abierta. Entonces, la inteligencia artificial está representando en muchas ocasiones una "salida fácil", en la que el ser humano ya no tiene que esforzarse por nada ni tiene que preocuparse por nada, porque con "un _chatazo_" queda, y al final toda nuestra carrera académica y/o profesional se termina basando en un mérito que le pertenece a ChatGPT, mas no a nosotros. Se está evadiendo al pensamiento, al criterio, y al esfuerzo propios.

Por otro lado tenemos lo que para mí es lo más alarmante. La inteligencia artificial consume _demasiados_ recursos. Para que ésta pueda funcionar como lo hace hoy en día se necesitan computadoras y servidores que consumen una cantidad gigantesca de electricidad y de agua, y que producen también demasiado dióxido de carbono. Investigadores de la Universidad de Massachusetts calcularon que la cantidad de energía que utilizan los LLM actualmente produce en promedio doscientos ochenta y tres mil kilos de dióxido de carbono, y el _Business Insider_ ha reportado que "ChatGPT consume el equivalente a una botella de agua potable por cada 20 o 50 avisos que recibe", debido a que esta agua se usa para refrigerar los servidores que lo operan, que deben permanecer a una temperatura baja. Para 2040 se espera que la IA represente el 14% de las emisiones globales de CO<sub>2</sub> [[5](https://www.businessinsider.es/ia-cambiandolo-todo-tambien-medioambiente-1304566)] [[6](https://www.ecoticias.com/co2/inteligencia-artificial-co2)].

Se espera que, dentro de unos años, la IA termine acercándose mucho &mdash;si no sobrepasándose&mdash; al consumo energético y producción de GEI derivados de la quema de combustibles fósiles. Es decir, la IA poco a poco está siendo un peligro cada vez mayor para el medio ambiente. Cada vez que utilizamos ChatGPT, Gemini o alguno de estos servicios populares estamos contaminando muchísimo más de lo que contaminaríamos en toda nuestra vida si no los usáramos, y con ello estamos acelerando el calentamiento global y el cambio climático.

Esto no significa que yo esté en contra de _toda_ la IA; en muchas ocasiones se ha utilizado para cosas buenas y que no le quitan el mérito a seres humanos, siendo el ejemplo más notable [la canción de The Beatles](https://inv.nadeko.net/watch?v=Opxhh9Oh3rg), además de que también existen los _modelos de lenguaje pequeños_, también conocidos como _SLMs_, que son en gran medida ligeros y autohosteables y que, por ende, son mucho más amigables con el medio ambiente. Muchos de estos SLMs son software libre, o por lo menos son open-source, como [Phi](https://es.wired.com/articulos/microsoft-presenta-phi-3-mini-un-diminuto-modelo-ia), [Mistral](https://mistral.ai/) o [Llama](https://llama.meta.com/). Pienso que es mucho mejor utilizar estas inteligencias artificiales, incluso autohostéandolas si se puede, para así no solamente no regalarle nuestra información personal a una empresa de IA que después la vende a empresas, gobiernos y _data-brokers_, sino para además poder beneficiarnos de las ventajas que plantean las IAs sin con ello destruir nuestro planeta.

También estoy a favor del uso moderado de la IA. Personalmente la llego a utilizar para casos puntuales que definitivamente no puedo encontrar en internet, ni que tampoco soy capaz de deducir por mi cuenta (por ejemplo ayer, que quise ver si la IA podía darme la letra de una canción que no encuentro en ningún lado, y que no pudo). No la suelo emplear para nada más. 

Existe una campaña de la cual participo llamada [Not By AI](https://notbyai.fyi/) que, bajo la premisa de que en 2025 hasta el 90% del contenido en Internet podría ser generado por IA, propone la creación de contenidos propios y originales en lugar de depender de ésta, que al final va a terminar estancando el desarrollo de Internet debido al abuso del reciclaje de lo ya existente. Todas las entradas de este blog tienen la frase "escrito por un humano, no por IA", que es la insignia proporcionada por Not By AI que informalmente "certifica" que este blog es escrito por un ser humano, y no por un LLM.

Está bien usar la inteligencia artificial; es probablemente el logro más importante alcanzado por el ser humano hasta ahora, pero no es correcto abusar de su uso, ni tampoco está bien hacer trampa con ella. Me parece mucho menos correcto destruir nuestro planeta y extinguir sus formas de vida por querer aprovechar los beneficios que ofrece. ¡Usemos la IA como una herramienta, no como nuestro sustituto, ni como un arma ecocida!
